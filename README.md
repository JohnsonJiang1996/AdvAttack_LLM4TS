ğŸ”’ Adversarial Attacks on LLMs for Time Series ForecastingğŸš€
Welcome to the Adversarial Time Series LLMs repository! If you've ever wondered whether Large Language Models (LLMs) could predict the future (literally, in time series forecasting), weâ€™re here to unveil the good, the bad, and the adversarially ugly truths.
ğŸ“š Whatâ€™s This All About?
LLMs have made waves in time series forecastingâ€”handling everything from predicting stock trends to weather patterns with their uncanny ability to process sequential data. But here's the catch: they aren't as invincible as they seem.

This repo dives deep into:

ğŸš§ How adversarial attacks can break LLMsâ€™ predictive prowess.
ğŸ› ï¸ A targeted adversarial attack framework for LLM-based forecasting models.
ğŸ“‰ Experiments demonstrating how subtle data perturbations can turn robust predictions into a chaotic mess of randomness.

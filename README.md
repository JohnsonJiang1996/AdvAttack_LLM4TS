🔒 Adversarial Attacks on LLMs for Time Series Forecasting🚀
Welcome to the Adversarial Time Series LLMs repository! If you've ever wondered whether Large Language Models (LLMs) could predict the future (literally, in time series forecasting), we’re here to unveil the good, the bad, and the adversarially ugly truths.
📚 What’s This All About?
LLMs have made waves in time series forecasting—handling everything from predicting stock trends to weather patterns with their uncanny ability to process sequential data. But here's the catch: they aren't as invincible as they seem.

This repo dives deep into:

🚧 How adversarial attacks can break LLMs’ predictive prowess.
🛠️ A targeted adversarial attack framework for LLM-based forecasting models.
📉 Experiments demonstrating how subtle data perturbations can turn robust predictions into a chaotic mess of randomness.
